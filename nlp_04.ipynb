{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec40a3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8750\n",
      "2066\n",
      "1448\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "files= ['sss_01_01.txt','sss_01_02.txt','sss_01_03.txt','sss_01_04.txt','sss_01_05.txt']\n",
    "data= ''\n",
    "for file in files:\n",
    "    f= open(\"sss/\"+file, 'r')\n",
    "    data+= f.read()\n",
    "data= data.lower()\n",
    "data= re.sub(\"[.\\“”:?!;,()-]\",\"\\n\",data)\n",
    "data= re.sub(\"(\\s[‘’])|([‘’]\\s)\",\"\\n\",data)\n",
    "data= re.sub(\"[‘’]s\",\"\",data)\n",
    "#print(data)\n",
    "words= data.splitlines()\n",
    "sentences= words\n",
    "words= [w.split(' ') for w in words]\n",
    "words= sum(words,[])\n",
    "words= [w.strip() for w in words]\n",
    "words= [w for w in words if len(w) >= 2]\n",
    "word_set= list(set(words))\n",
    "word_set.sort()\n",
    "wc= {w:0 for w in word_set}\n",
    "for w in words:\n",
    "    wc[w]+= 1\n",
    "wc= {k:v for k,v in sorted(wc.items(), key= lambda item: item[1], reverse=True)}\n",
    "print(len(words))\n",
    "print(len(wc))\n",
    "print(len(sentences))\n",
    "#print((sorted(wc.items(), key= lambda item: item[1], reverse=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f590c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1448, 2066)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec= CountVectorizer()\n",
    "output= vec.fit_transform(sentences)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0363fcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2066\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "cvec_set= set(vec.get_feature_names_out())\n",
    "print(len(cvec_set))\n",
    "print(set(word_set) - cvec_set)\n",
    "print(cvec_set - set(word_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee0b7580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1448\n",
      "2066\n",
      "0.9628234486457137\n",
      "3.695880468685084\n",
      "0.8178196065971154\n",
      "5.044682602125757\n",
      "5.044682602125757\n",
      "0.587940674131566\n",
      "5.044682602125757\n",
      "2.6003957468501753\n",
      "2.2183490192549016\n",
      "school\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "total_documents= len(sentences)\n",
    "word_index= {}\n",
    "i= 0\n",
    "for w in word_set:\n",
    "    word_index[w]= i;\n",
    "    i= i+1;\n",
    "#print(word_index)\n",
    "df= {}\n",
    "for w in word_set:\n",
    "    df[w]= 0;\n",
    "    for s in sentences:\n",
    "        if w in s:\n",
    "            df[w]+= 1;\n",
    "#print(df)\n",
    "vectors= []\n",
    "for s in sentences:\n",
    "    vec= np.zeros((len(word_set)))\n",
    "    for w in set(s.split(' ')):\n",
    "        if w in word_set:\n",
    "            idf= np.log(total_documents/df[w])\n",
    "            tf= np.log(len([t for t in s.split(' ') if t == w]) + 1)\n",
    "            vec[word_index[w]]= tf * idf\n",
    "    vectors.append(vec)\n",
    "print(len(vectors))\n",
    "print(len(vectors[0]))\n",
    "for v in vectors[0]:\n",
    "    if v > 0:\n",
    "        print(v)\n",
    "print(word_set[1547])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6ed52f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2066\n",
      "set()\n",
      "set()\n",
      "(1448, 2066)\n",
      "  (0, 1547)\t0.4284805406475236\n",
      "  (0, 852)\t0.4284805406475236\n",
      "  (0, 1799)\t0.11470156326175966\n",
      "  (0, 911)\t0.1880940639597031\n",
      "  (0, 1722)\t0.4284805406475236\n",
      "  (0, 1927)\t0.4284805406475236\n",
      "  (0, 148)\t0.29051986642385236\n",
      "  (0, 1972)\t0.2755111115839211\n",
      "  (0, 1997)\t0.23827235307713396\n",
      "school\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer= TfidfVectorizer()\n",
    "tfidf_vec= vectorizer.fit_transform(sentences)\n",
    "tfidf_word_set= set(vectorizer.get_feature_names_out())\n",
    "print(len(tfidf_word_set))\n",
    "print(tfidf_word_set - set(word_set))\n",
    "print(set(word_set) - tfidf_word_set)\n",
    "print(tfidf_vec.shape)\n",
    "print(tfidf_vec[0])\n",
    "print(vectorizer.get_feature_names_out()[1547])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
